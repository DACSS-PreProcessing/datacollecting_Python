{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/DACSS-PreProcessing/session1_main/blob/main/pics/LogoSimple.png?raw=true\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Collection in Python\n",
    "\n",
    "### Prof. José Manuel Magallanes, PhD \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beginning'></a>\n",
    "\n",
    "Let me share some code to get data. Let me show you how to deal with the following cases:\n",
    "\n",
    "1. [Propietary software.](#part1) \n",
    "2. [Ad-hoc collection.](#part2) \n",
    "3. [Use of APIs.](#part3) \n",
    "4. [Scraping webpages.](#part4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the location of your files is extremely important. If you have created a folder name \"myProject\", and your code is saved  in that folder, then \"myProject\" is your the root folder. In general, you will create other folders inside the root. One of those will be for your data. In any case, you should become familiar with some important commands in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is located my current code?\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above gave you your current location, if it is not what you expected, you can change it with another command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above gave you your current location. As you see, you have a _sepator_ ( \\, \\\\, /, //) used to create a path to the folder. This separator may vary depending on what platform (operating system)  you have. To make this simple, you simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "fileToRead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object _fileToRead_ has the right name of the path, because **os.path.join**  creates a path using the **right** _separators_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Collecting data from propietary software\n",
    "\n",
    "Let's start with data from SPSS and STATA, very common in public policy schools. To work with these kind of files, we will simply use *pandas*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I using a file from the American National Election Studies (ANES). This is a rather big file, so let me select some variables (\"libcpre_self\",\"libcpo_self\",a couple of question pre and post elections asking respondents to place themselves on a seven point scale ranging from ‘extremely liberal’ to ‘extremely conservative’) and create a data frame with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsOfInterest=[\"libcpre_self\",\"libcpo_self\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a Stata file into pandas is quite easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "dataStata=pd.read_stata(fileToRead,columns=varsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can read SPSS, if you previously install **pyreadstat**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName=\"anes_timeseries_2012.sav\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "\n",
    "dataSpss=pd.read_spss(fileToRead,usecols=varsOfInterest)\n",
    "dataSpss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "## Collecting your ad-hoc data\n",
    "\n",
    "Let me assume you are answering some questions in this [form](https://forms.gle/6Ga61ifjCjo3j3YF6).\n",
    "\n",
    "After completing the survey, your answers are saved in an spreadsheet, which you should publish as a CSV file. Then, you can read it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "link='https://docs.google.com/spreadsheets/d/1MrWp0kVtNGzTOmhuexjsIaZ9HpSv2X8RZsZ-KuEC4A8/pub?gid=1044145359&single=true&output=csv'\n",
    "\n",
    "myData = pd.read_csv(link)\n",
    "\n",
    "# here it is:\n",
    "myData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "-----\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "## Collecting data from APIs\n",
    "\n",
    "There are organizations, public and private, that have an open data policy that allows people to access their repositories dynamically. You can get that data in CSV format if available, but the data is always in  XML or JSON format, which are data containers that store data in an *associative array* structure. Let me get the data about [Fire 9-1-1  calls  from Seattle](https://dev.socrata.com/foundry/data.seattle.gov/kzjm-xkqj):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# where is it online?\n",
    "url = \"https://data.seattle.gov/resource/kzjm-xkqj.json\"\n",
    "\n",
    "# Go for the data:\n",
    "response = requests.get(url)\n",
    "\n",
    "# If we got the data:\n",
    "if response.status_code == 200:\n",
    "    data911 = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can turn it easily into a pandas data frame:\n",
    "import pandas as pd\n",
    "data911DF=pd.DataFrame(data911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you are...\n",
    "data911DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you got only 1000 rows, you may try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sodapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"data.seattle.gov\", None)\n",
    "results = client.get(\"kzjm-xkqj\", limit=3000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "## Collecting data by scraping\n",
    "\n",
    "We are going to get the data from a table from this [wikipage](https://en.wikipedia.org/wiki/List_of_freedom_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install html5lib lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables=pd.read_html(io=wikiLink,flavor='bs4',attrs={\"class\":\"wikitable\"},match='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are there?\n",
    "len(wikiTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, I just pick the one I need:\n",
    "wikiTable=wikiTables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do you have:\n",
    "wikiTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Reminder for Deliverable 1:\n",
    "\n",
    "Start collecting the data you will use in the course. If you have the files, save them in folder inside your repo. If the files are above 100 Mb, you may try amazonws instead, or use GIT-LFS. For sure, there might be cases where you decide not to commit/push your local data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
